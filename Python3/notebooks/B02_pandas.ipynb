{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:red;background-color:black\">\n",
    "Diamond Light Source\n",
    "\n",
    "<h1 style=\"color:red;background-color:antiquewhite\"> Python Fundamentals: Pandas</h1>  \n",
    "\n",
    "Â©2000-20 Chris Seddon \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the following cell to activate styling for this tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>/* GLOBALS */\n",
       "/* body {background-color: #f7f7f7;} */\n",
       ".text_cell {background-color: cornsilk;}\n",
       ".code_cell { background-color: lightskyblue; }\n",
       ".selected { background-color: peachpuff; }\n",
       ".output { background-color: aliceblue; }\n",
       "\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(f\"<style>{open('my.css').read()}</style>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample: 1\n",
    "Pandas is a very popular Data Analysis library that is built on top of Numpy.  Pandas excels at two dimensional problems.  \n",
    "\n",
    "For example consider the file `data/sample.csv`.  I've printed it out below for convenience:\n",
    "<pre>\n",
    "Name,   County,         Gender, Age, Height, Weight\n",
    "\n",
    "Jane,   Berkshire,      F,      30,  178,    68\n",
    "Peter,  Notts,          M,      27,  170,    59\n",
    "Silvia, Yorkshire,      F,      42,  183,    66\n",
    "John,   Dorset,         M,      54,  173,    80\n",
    "Bill,   Surrey,         M,      31,  169,    70\n",
    "Ali,    Essex,          M,      30,  181,    75\n",
    "Zoe,    Cambridgeshire, F,      25,  180,    72\n",
    "</pre>\n",
    "\n",
    "This is a comma separated file with 6 fields, a title row and 7 other rows.  We can use Pandas to read this file into memory as a dataframe.  Dataframes are two dimensional data structures that are central to Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     Name          County Gender  Age  Height  Weight\n",
      "0    Jane       Berkshire      F   30     178      68\n",
      "1   Peter           Notts      M   27     170      59\n",
      "2  Silvia       Yorkshire      F   42     183      66\n",
      "3    John          Dorset      M   54     173      80\n",
      "4    Bill          Surrey      M   31     169      70\n",
      "5     Ali           Essex      M   30     181      75\n",
      "6     Zoe  Cambridgeshire      F   25     180      72\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/sample.csv\", engine='python', skipinitialspace=True)\n",
    "print(type(df))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample: 2\n",
    "Without the \"skipinitialspace=True\" parameter, the column headings end up including spaces (this will cause problems identifying columns).\n",
    "\n",
    "Note that Pandas creates a numerical index column (0 to 6).  All Pandas dataframes have an index column.  The index doesn't have to be an integer; we can choose one of the columns as the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "                County Gender  Age  Height  Weight\n",
      "Name                                              \n",
      "Jane         Berkshire      F   30     178      68\n",
      "Peter            Notts      M   27     170      59\n",
      "Silvia       Yorkshire      F   42     183      66\n",
      "John            Dorset      M   54     173      80\n",
      "Bill            Surrey      M   31     169      70\n",
      "Ali              Essex      M   30     181      75\n",
      "Zoe     Cambridgeshire      F   25     180      72\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/sample.csv\", skipinitialspace=True, index_col=0)\n",
    "print(type(df))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample: 3\n",
    "You'll notice the heading for the index is printed below all the other column headings so that it stands out.  The index values can be used to identify the rows, although it doesn't have to contain unique entries.\n",
    "\n",
    "To begin with we will print out just the index: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Jane', 'Peter', 'Silvia', 'John', 'Bill', 'Ali', 'Zoe'], dtype='object', name='Name')\n"
     ]
    }
   ],
   "source": [
    "print(df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample: 4\n",
    "Next, just the column headings (note that the index is not included):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['County', 'Gender', 'Age', 'Height', 'Weight'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample: 5\n",
    "Often we want to extract the data from the dataframe and copy it to a two dimensional Numpy array.  \n",
    "\n",
    "We do this with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df.values))\n",
    "print(df.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample: 6\n",
    "Now we create a new dataframe with the \"County\" and \"Age\" columns.  Note we will still keep the index column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[['County', 'Age']]\n",
    "print(type(df2))\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample: 7\n",
    "If we want to create a new dataframe with just one column, we still need to use two sets of [ ] brackets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[['County']]\n",
    "print(type(df2))\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample: 8\n",
    "If we only use a single set of [ ] brackets, we get a series rather than a dataframe.  A series is a Pandas one dimensional array (including an index):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = df['County']\n",
    "print(type(series))\n",
    "print(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample: 9\n",
    "Pandas has two methods of searching for data based on index:\n",
    "\n",
    "The \".loc\" method uses the index of the dataset.  A lot of datasets have an index of integers, but the index can be any data type, often \"str\".  \n",
    "The \".iloc\" metods works with integers - the postion of the index (starting from 0).\n",
    "\n",
    "Let's look at some \".loc\" examples.  \n",
    "\n",
    "* Select a single row by index \"Peter\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = df.loc['Peter']\n",
    "print(type(series))\n",
    "print(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample: 10\n",
    "* select an inclusive slice of rows between \"Peter\" and \"Bill\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.loc['Peter':'Bill']\n",
    "print(type(df2))\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample: 11\n",
    "* select rows \"Peter\" and \"Bill\" and columns \"County\", \"Height\" and \"Weight\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.loc[['Peter', 'Bill'], ['County', 'Height', 'Weight']]\n",
    "#print(df.loc[['Peter', 'Bill'], ['County', 'Height', 'Weight']])\n",
    "\n",
    "print(type(df2))\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample: 12\n",
    "* select all rows, but only columns \"County\" and \"Gender\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.loc[:, ['County', 'Gender']]\n",
    "print(type(df2))\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample: 13\n",
    "The \".iloc\" method works as above, except we substitute integers for the index.\n",
    "\n",
    "* select row 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = df.iloc[3]\n",
    "print(type(series))\n",
    "print(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample: 14\n",
    "* select rows 3, 6, 2 and 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.iloc[[3, 6, 2, 4]]\n",
    "print(type(df2))\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample: 15\n",
    "* row 3 column 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = df.iloc[3, 2]\n",
    "print(type(value))\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lerwick : 1\n",
    "Now we seen hoe Pandas works on a simple file we turn out attention to some real data.  \n",
    "\n",
    "The file \"data/lerwick.txt\" contains met office data that is published on their web site.  Let's take a look at it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat data/lerwick.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lerwick : 2\n",
    "When working with real data, we find some rows have missing data and other rows have extra characters like * and #.  Other rows have an additional column with the string \"Provisional\":\n",
    "<pre>\n",
    "   1982   3    6.7     2.7       1   134.5   108.5*\n",
    "   2010   1    4.3     0.5      13   113.7    38.5*\n",
    "   2012   4    7.1     2.5       6    93.3*  108.5#\n",
    "   2012   5   10.1     4.1       2    71.7*  227.7#\n",
    "   2015   9   13.3*    9.8*      0*   88.2*   38.5#  Provisional\n",
    "</pre>\n",
    "\n",
    "Furthermore, the file is not a \"comma seperated value\" file.  Nevertheless, Pandas can still read data from this file.  Suprisingly, Pandas still uses \"read_csv\" even though the file doesn't have any commas.  However we now need to specify a separator to define the field boundaries.\n",
    "\n",
    "The separator between fields as any combinations of spaces, *s and #s.  We define the separator as a regular expression (regex): <pre>[ *#]+</pre>\n",
    "Note that if we use a regex as a separator, we have to use the \"python\" engine (as opposed to the \"C\" engine which does not support regex, but is faster than the \"python\" engine).  Additionally, in the above file, we ignore the first 7 lines and rather than using the headings present in the file (awkward because they span two lines) we define out own headings.\n",
    "\n",
    "We can now read from the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.precision', 1)\n",
    "pd.set_option('display.width', None)        # None means all data displayed\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "column_names = ['year', 'month', 'tmax', 'tmin', 'air-frost-days', 'rain(mm)', 'sun(hours)', 'comment']\n",
    "lerwick_data = pd.read_csv(\"data/lerwick.txt\", \n",
    "                           skiprows = 7,\n",
    "                           engine = 'python',\n",
    "                           names = column_names, \n",
    "                           skipinitialspace = True, \n",
    "                           sep = '[*# ]+')\n",
    "print(lerwick_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lerwick : 3\n",
    "Python provides a few basic methods to get to the feel of the dataframe:  \n",
    "\n",
    "|   |   |   |\n",
    "|:---|---|---|\n",
    "| head(): | print first five rows |\n",
    "| tail(): | print last five rows |\n",
    "| sample(5) | print random sample 5 of rows |\n",
    "| shape: | print number of rows/columns in a tuple |\n",
    "| describe(): | calculate measures of central tendency |\n",
    "| info(): | print memory footprint and datatypes |\n",
    "\n",
    "Let's take a look at the first 5 rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lerwick_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lerwick : 4\n",
    "... and the last 5 rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lerwick_data.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lerwick : 5\n",
    "A random sample of 5 rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lerwick_data.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lerwick : 6\n",
    "The shape of the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lerwick_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lerwick : 7\n",
    "Various statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lerwick_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lerwick : 8\n",
    "Memory footprint etc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lerwick_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lerwick : 9\n",
    "Before we move on to another dataset, one last example with the Lerwick data.  \n",
    "\n",
    "Lets print out the beginning and end of the dataframe (20 rows in total), sorted by \"tmax\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmax = lerwick_data.sort_values('tmax', axis=0, ascending=False)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "print(tmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oxford : 1\n",
    "Now we move on to a more advanced example.  \n",
    "\n",
    "This time we are using the Met Office data for Oxford; this data is much older and stretches back to 1830: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "head -20 data/oxford.txt\n",
    "echo \"...\"\n",
    "tail -20 data/oxford.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oxford: 2\n",
    "Before we look at the details, it would be helpful to run the full example.  We can highlight the important points afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "pd.set_option('display.precision', 1)\n",
    "pd.set_option('display.width', 100)\n",
    "    \n",
    "def main(): \n",
    "    # set column names and read in data from file\n",
    "    column_names = ['year', 'month', 'tmax', 'tmin', 'air-frost-days', 'rain(mm)', 'sun(hours)', 'comment']\n",
    "    oxford_data = pd.read_csv(\"data/oxford.txt\", \n",
    "                              engine = 'python', \n",
    "                              skiprows = 7, \n",
    "                              names = column_names, \n",
    "                              na_values = ['---'], \n",
    "                              skipinitialspace = True, \n",
    "                              sep = '[*# ]+')\n",
    "\n",
    "    # some of the tmin values are missing, so drop these rows\n",
    "    oxford_data.dropna()\n",
    "    \n",
    "    # create a new column from year and month columns\n",
    "    oxford_data['period'] = oxford_data.apply(\n",
    "        lambda row : (row.year//4)*4, raw = True, \n",
    "        axis = 1\n",
    "        )\n",
    "\n",
    "    # drop columns we are not using (not necessary)\n",
    "    oxford_data.drop(['year', 'month', 'air-frost-days', 'rain(mm)', 'sun(hours)', 'comment'], axis = 1, inplace = True)\n",
    "\n",
    "    # group results into 4 year periods\n",
    "    # the new column (period) becomes the index\n",
    "    summary = oxford_data.groupby(['period']).aggregate(np.mean)\n",
    "\n",
    "    # plot the data\n",
    "    ax = summary.plot(figsize=(10, 6), \n",
    "                               title = 'Oxford : Average Min and Max Temperatures (over 4 year periods)', \n",
    "                               # x defaults to index\n",
    "                               y = ['tmin', 'tmax'], \n",
    "                               color = ['red', 'green'], \n",
    "                               kind = 'bar')\n",
    "\n",
    "    ax.set_xlabel(\"4 year period\")\n",
    "    ax.set_ylabel(f\"{chr(0x2103)}\")     # degrees C\n",
    "    for item in [ax. title, ax.xaxis.label, ax.yaxis.label]:\n",
    "        item.set_fontsize(20)\n",
    "    plt.show()\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oxford : 2\n",
    "There are two key lines in the above example.  \n",
    "The first is where we create a new column: \n",
    "\n",
    "<pre>\n",
    "oxford_data['period'] = oxford_data.apply(\n",
    "        lambda row : (row.year//4)*4, \n",
    "        raw = True, \n",
    "        axis = 1\n",
    "        )\n",
    "</pre>\n",
    "\n",
    "The \"apply\" method is used to apply a function along an axis of the DataFrame, often to create a new row or column.  In this case we are creating new column for each row (axis=1).  \n",
    "\n",
    "The \"apply\" method takes a lambda to calculate the new values for the column:<pre> lambda row : (row.year//4)*4</pre>\n",
    "The lambda works on each row, taking the year and rounding it to the nearest 4 year period.  By the way, the \"row\" input can be supplied as a series (row=False) or as a Numpy array (row=True)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['year', 'month', 'tmax', 'tmin', 'air-frost-days', 'rain(mm)', 'sun(hours)', 'comment']\n",
    "oxford_data = pd.read_csv(\"data/oxford.txt\", \n",
    "                          engine = 'python', \n",
    "                          skiprows = 7, \n",
    "                          names = column_names, \n",
    "                          na_values = ['---'], \n",
    "                          skipinitialspace = True, \n",
    "                          sep = '[*# ]+')\n",
    "\n",
    "# some of the tmin values are missing, so drop these rows\n",
    "oxford_data.dropna()\n",
    "    \n",
    "oxford_data['period'] = oxford_data.apply(\n",
    "        lambda row : (row.year//4)*4, raw = True, \n",
    "        axis = 1\n",
    "        )\n",
    "print(oxford_data[750:760])\n",
    "print(oxford_data[846:856])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oxford : 3\n",
    "There is far too much data to plot month by month, so we have aggregated the \"min\" and \"max\" average temperatures over 48 month periods.  That's why we created the \"period\" column.\n",
    "\n",
    "The second key line is where we aggregate the data into groups of 48 (rows with the same value of \"period\").  In this example we create a new dataframe with the \"np.mean\" of each of the 48 rows.\n",
    "\n",
    "<pre>\n",
    "summary = oxford_data.groupby(['period']).aggregate(np.mean)\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns we are not using (not necessary)\n",
    "oxford_data.drop(['year', 'month', 'air-frost-days', 'rain(mm)', 'sun(hours)', 'comment'], axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "# group results into 4 year periods\n",
    "# the groupby column (period) becomes the index\n",
    "summary = oxford_data.groupby(['period']).aggregate(np.mean)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Olympics: 1\n",
    "Our new example shows how to extract data from a dataframe based on conditions.  \n",
    "\n",
    "We will display all countries who were awarded more golds than South Korea.  Let's look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "head -25 data/olympics_2012_medal_table.txt\n",
    "echo \"...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Olympics: 2\n",
    "Here is the full example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pylab as pl\n",
    "pd.set_option('display.width', 100)\n",
    "\n",
    "# read in medal table (n.b. delimiters contain at least 2 spaces and sometimes a bracket) \n",
    "medal_table = pd.read_csv(\"data/olympics_2012_medal_table.txt\",\n",
    "                           engine = 'python',\n",
    "                           skiprows = 1,\n",
    "                           sep = '[ )(]{2,}')\n",
    "\n",
    "korean_golds = medal_table[medal_table.Id == \"KOR\"][\"Gold\"].values[0]\n",
    "print(\"Korea earned {} golds\".format(korean_golds))\n",
    "print(\"\\nCountries with more golds than South Korea:\")\n",
    "result = medal_table[medal_table.Gold > korean_golds][[\"Country\", \"Gold\"]]\n",
    "print(result.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Olympics: 3\n",
    "In the above example our first problem is to determine the field delimeter.  A careful look at the data reveals spaces in the Country field, but there are never more than 1 consecutive space.  If we include space and ( ) brackets as delimiter characters we notice that every field has at least 2 delimeter characters.  One of the trickest rows is: <pre>\n",
    "19   Czech Republic (CZE)     4     3      3    10\n",
    "</pre>\n",
    "Here the \"Country\" and \"Id\" columns are separated by \" (\".  This is the minimum 2 character separator.  \n",
    "\n",
    "So we can define the separator as the regex with the three delimeter characters space and the two brackets ( ) as:<pre>[ )(] {2,}</pre>\n",
    "where `{2,}` means 2 or more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(medal_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Olympics: 4\n",
    "To determine how many golds were awarded to South Korea, we extract a series.  Unfortunately the series include (as always) the index.  What we need to do is convert the series to a Numpy array and extract the first element of that array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "korean_golds = medal_table[medal_table.Id == \"KOR\"][\"Gold\"]\n",
    "print(type(korean_golds))\n",
    "print(f\"{korean_golds}\\n\")\n",
    "\n",
    "korean_golds = medal_table[medal_table.Id == \"KOR\"][\"Gold\"].values\n",
    "print(type(korean_golds))\n",
    "print(f\"{korean_golds}\\n\")\n",
    "\n",
    "korean_golds = medal_table[medal_table.Id == \"KOR\"][\"Gold\"].values[0]\n",
    "print(type(korean_golds))\n",
    "print(f\"{korean_golds}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excel: 1\n",
    "Pandas makes it easy to read and write dataframes from/to Excel spreadshhets.  Other Python modules can also be used:\n",
    "<a href=\"https://openpyxl.readthedocs.io/en/stable/\">openpyxl</a>\n",
    "\n",
    "Here is the \"write\" example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pylab as pl\n",
    "pd.set_option('display.precision', 1)\n",
    "pd.set_option('display.width', 100)\n",
    "\n",
    "def main(): \n",
    "    column_names = ['year', 'month', 'tmax', 'tmin', 'air-frost-days', 'rain(mm)', 'sun(hours)', 'comment']\n",
    "    lerwick_data = pd.read_csv(\"data/lerwick.txt\", \n",
    "                               skiprows = 8, \n",
    "                               names = column_names, \n",
    "                               skipinitialspace = True,\n",
    "                               engine = 'python', \n",
    "                               sep = '[*# ]+')\n",
    "    lerwick_data.to_excel('data/lerwick.xlsx', index = False)\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excel: 2\n",
    "Here is the \"read\" example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pylab as pl\n",
    "pd.set_option('display.precision', 1)\n",
    "pd.set_option('display.width', 100)\n",
    "\n",
    "def main(): \n",
    "    lerwick_data_df = pd.read_excel('data/lerwick.xlsx', 'Sheet1')\n",
    "    print(lerwick_data_df)\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
